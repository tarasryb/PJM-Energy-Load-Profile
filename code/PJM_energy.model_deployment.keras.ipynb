{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==2.4.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (2.4.5)\r\n",
      "Requirement already satisfied: py4j==0.10.7 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyspark==2.4.5) (0.10.7)\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3 style='color:green;'>Pyspark installed</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "!pip install pyspark==2.4.5\n",
    "HTML(\"<h3 style='color:green;'>Pyspark installed</h3>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.2.0rc0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (2.2.0rc0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (3.2.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.11.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.16.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.19.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (2.10.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.4.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (3.11.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (0.32.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (0.7.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0rc0) (2.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow==2.2.0rc0) (40.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (2.21.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (3.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (1.19.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (0.14.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (1.3.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (1.24.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.2.0rc0) (0.4.8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3 style='color:green;'>TensorFlow installed</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install tensorflow==2.2.0rc0\n",
    "HTML(\"<h3 style='color:green;'>TensorFlow installed</h3>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Pyspark OK"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mandatory\n",
    "\n",
    "#check Pyspark is installe\n",
    "from IPython.display import HTML\n",
    "h = HTML(\"Pyspark OK\")\n",
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "except ModuleNotFoundError as e:\n",
    "    h = HTML(\"<h3 style='color:red;'>!!!!! Please install pyspark - run previous cell !!!!!</h3>\")\n",
    "h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "SparkSession OK"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mandatory\n",
    "h = HTML(\"SparkSession OK\")\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    h = HTML(\"<h3 style='color:red;'>!!!!! Please restart your kernel after installing Apache Spark !!!!!</h3>\")\n",
    "\n",
    "h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "SparkContext OK"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mandatory\n",
    "h = HTML(\"SparkContext OK\")\n",
    "\n",
    "try:\n",
    "    sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .getOrCreate()\n",
    "except Error as e:\n",
    "    h = HTML(\"<h3 style='color:red;'>!!!!! SparkContext or SparkSession creation error !!!!!</h3>\")\n",
    "\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TensorFlow version OK"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "h = HTML(\"TensorFlow version OK\")\n",
    "\n",
    "if not tf.__version__ == '2.2.0-rc0':\n",
    "    print(tf.__version__)\n",
    "    h = HTML(\"<h3 style='color:red;'>Please upgrade to TensorFlow 2.2.0-rc0, or restart your Kernel (Kernel->Restart & Clear Output)</h3>\")\n",
    "\n",
    "h    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data From GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-13 19:33:37--  https://raw.githubusercontent.com/tarasryb/PJM-Energy-Load-Profile/master/data/pjm_AEP_normalized.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 914906 (893K) [text/plain]\n",
      "Saving to: ‘pjm_AEP_normalized.csv.1’\n",
      "\n",
      "100%[======================================>] 914,906     --.-K/s   in 0.03s   \n",
      "\n",
      "2020-07-13 19:33:37 (25.7 MB/s) - ‘pjm_AEP_normalized.csv.1’ saved [914906/914906]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/tarasryb/PJM-Energy-Load-Profile/master/data/pjm_AEP_normalized.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data file was downloaded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style=\"color:green\">pjm_AEP_normalized.csv file downloaded successfuly</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = !ls -l\n",
    "\n",
    "h = HTML('<h3 style=\"color:red\">Can not download pjm_AEP_normalized.csv file from GitHub</h3>')\n",
    "for st in res:\n",
    "    i = st.find('pjm_AEP_normalized.csv')\n",
    "    if i > 0:\n",
    "        h = HTML('<h3 style=\"color:green\">pjm_AEP_normalized.csv file downloaded successfuly</h3>')\n",
    "\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV file into PySpark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#read csv to Pyspark Dataframe\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"pjm_AEP_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- day: string (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      " |-- h_0: string (nullable = true)\n",
      " |-- h_1: string (nullable = true)\n",
      " |-- h_2: string (nullable = true)\n",
      " |-- h_3: string (nullable = true)\n",
      " |-- h_4: string (nullable = true)\n",
      " |-- h_5: string (nullable = true)\n",
      " |-- h_6: string (nullable = true)\n",
      " |-- h_7: string (nullable = true)\n",
      " |-- h_8: string (nullable = true)\n",
      " |-- h_9: string (nullable = true)\n",
      " |-- h_10: string (nullable = true)\n",
      " |-- h_11: string (nullable = true)\n",
      " |-- h_12: string (nullable = true)\n",
      " |-- h_13: string (nullable = true)\n",
      " |-- h_14: string (nullable = true)\n",
      " |-- h_15: string (nullable = true)\n",
      " |-- h_16: string (nullable = true)\n",
      " |-- h_17: string (nullable = true)\n",
      " |-- h_18: string (nullable = true)\n",
      " |-- h_19: string (nullable = true)\n",
      " |-- h_20: string (nullable = true)\n",
      " |-- h_21: string (nullable = true)\n",
      " |-- h_22: string (nullable = true)\n",
      " |-- h_23: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- day: string (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      " |-- h_0: double (nullable = true)\n",
      " |-- h_1: double (nullable = true)\n",
      " |-- h_2: double (nullable = true)\n",
      " |-- h_3: double (nullable = true)\n",
      " |-- h_4: double (nullable = true)\n",
      " |-- h_5: double (nullable = true)\n",
      " |-- h_6: double (nullable = true)\n",
      " |-- h_7: double (nullable = true)\n",
      " |-- h_8: double (nullable = true)\n",
      " |-- h_9: double (nullable = true)\n",
      " |-- h_10: double (nullable = true)\n",
      " |-- h_11: double (nullable = true)\n",
      " |-- h_12: double (nullable = true)\n",
      " |-- h_13: double (nullable = true)\n",
      " |-- h_14: double (nullable = true)\n",
      " |-- h_15: double (nullable = true)\n",
      " |-- h_16: double (nullable = true)\n",
      " |-- h_17: double (nullable = true)\n",
      " |-- h_18: double (nullable = true)\n",
      " |-- h_19: double (nullable = true)\n",
      " |-- h_20: double (nullable = true)\n",
      " |-- h_21: double (nullable = true)\n",
      " |-- h_22: double (nullable = true)\n",
      " |-- h_23: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1877"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cast all columns except Datetime to Double\n",
    "colList = df.columns\n",
    "colList.remove('day')\n",
    "colList.remove('ts')\n",
    "    \n",
    "for column in colList:\n",
    "    df = df.withColumn(column, col(column).cast(\"double\"))\n",
    "    \n",
    "df.printSchema()\n",
    "df.count()\n",
    "#df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train data set: extract winter and summer data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('pjm_AEP_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "winter_data = spark.sql(\"\"\"\n",
    "    select *\n",
    "        from pjm_AEP_normalized \n",
    "        where unix_timestamp(day, \"yyyy-MM-dd\") >= unix_timestamp(\"2015-12-01\", \"yyyy-MM-dd\")AND\n",
    "              unix_timestamp(day, \"yyyy-MM-dd\") <= unix_timestamp(\"2016-02-28\", \"yyyy-MM-dd\")\n",
    "        \n",
    "    \"\"\")\n",
    "print(winter_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "summer_data = spark.sql(\"\"\"\n",
    "    select *\n",
    "        from pjm_AEP_normalized \n",
    "        where unix_timestamp(day, \"yyyy-MM-dd\") >= unix_timestamp(\"2016-06-01\", \"yyyy-MM-dd\")AND\n",
    "              unix_timestamp(day, \"yyyy-MM-dd\") <= unix_timestamp(\"2016-08-29\", \"yyyy-MM-dd\")\n",
    "        \n",
    "    \"\"\")\n",
    "print(summer_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "winter_data = np.array(winter_data.select(\n",
    "    \"h_0\", \"h_1\", \"h_2\", \"h_3\", \"h_4\", \"h_5\", \"h_6\", \"h_7\", \"h_8\", \"h_9\", \"h_10\", \"h_11\",\n",
    "    \"h_12\", \"h_13\", \"h_14\", \"h_15\", \"h_16\", \"h_17\", \"h_18\", \"h_19\", \"h_20\", \"h_21\", \"h_22\", \"h_23\"    \n",
    "    ).collect())\n",
    "\n",
    "summer_data = np.array(summer_data.select(\n",
    "    \"h_0\", \"h_1\", \"h_2\", \"h_3\", \"h_4\", \"h_5\", \"h_6\", \"h_7\", \"h_8\", \"h_9\", \"h_10\", \"h_11\",\n",
    "    \"h_12\", \"h_13\", \"h_14\", \"h_15\", \"h_16\", \"h_17\", \"h_18\", \"h_19\", \"h_20\", \"h_21\", \"h_22\", \"h_23\"    \n",
    "    ).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 24)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winter_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 24)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30340414, 0.23288033, 0.17535295, ..., 0.52665259, 0.51233672,\n",
       "        0.42439636],\n",
       "       [0.33665391, 0.25201214, 0.20880063, ..., 0.47644808, 0.45573295,\n",
       "        0.38633065],\n",
       "       [0.30525135, 0.23829001, 0.19408893, ..., 0.46615649, 0.44656287,\n",
       "        0.38276818],\n",
       "       ...,\n",
       "       [0.42822272, 0.34734134, 0.29337643, ..., 0.57468004, 0.52130888,\n",
       "        0.45118089],\n",
       "       [0.36944188, 0.30459163, 0.25214408, ..., 0.58840216, 0.53450323,\n",
       "        0.44069138],\n",
       "       [0.36442802, 0.3041958 , 0.2518802 , ..., 0.69527642, 0.62607204,\n",
       "        0.50672912]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#???\n",
    "winter_data.reshape(90, 24)\n",
    "summer_data.reshape(90, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "from queue import Queue\n",
    "import pandas as pd\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 24\n",
    "samples = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        sys.stdout.write(str(logs.get('loss'))+str(', '))\n",
    "        sys.stdout.flush()\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        \n",
    "lr = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_neurons_layer1 = 24 \n",
    "number_of_neurons_layer2 = 24 \n",
    "number_of_neurons_layer3 = 1 \n",
    "number_of_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "from tensorflow.keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(number_of_neurons_layer1,input_shape=(dim, ), activation='relu'))\n",
    "model.add(Dense(number_of_neurons_layer2, activation='relu'))\n",
    "model.add(Dense(number_of_neurons_layer3, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "\n",
    "def train(data,label):\n",
    "    model.fit(data, label, epochs=number_of_epochs, batch_size=72, validation_data=(data, label), verbose=1, shuffle=True,callbacks=[lr]) #validation_data=(data, label)\n",
    "\n",
    "def score(data):\n",
    "    return model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create labels for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_label = np.repeat(1, 90)\n",
    "winter_label.shape = (90, 1)\n",
    "summer_label = np.repeat(0, 90)\n",
    "summer_label.shape = (90, 1)\n",
    "both_label = np.vstack((winter_label,summer_label))\n",
    "\n",
    "train_winter = np.hstack((winter_data,winter_label))\n",
    "train_summer = np.hstack((summer_data,summer_label))\n",
    "\n",
    "both_data = np.vstack((winter_data, summer_data))\n",
    "train_both = np.vstack((train_winter,train_summer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 25)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_both.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.7341 - val_loss: 0.721541230511665344,\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7296 - val_loss: 0.718896198010444641,\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7276 - val_loss: 0.716076113629341125,\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7228 - val_loss: 0.713128273749351501,\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7211 - val_loss: 0.710610683822631836,\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7205 - val_loss: 0.708504639315605164,\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7153 - val_loss: 0.706352859568595886,\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7127 - val_loss: 0.704127010226249695,\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7088 - val_loss: 0.702188322639465332,\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7082 - val_loss: 0.70078202600479126,\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7069 - val_loss: 0.699568924307823181,\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7034 - val_loss: 0.697633887505531311,\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7020 - val_loss: 0.69641972246170044,\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7019 - val_loss: 0.695418739581108093,\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6994 - val_loss: 0.694093729472160339,\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6975 - val_loss: 0.692774513530731201,\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6966 - val_loss: 0.6917613073348999,\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6945 - val_loss: 0.69084692730903625,\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6944 - val_loss: 0.690144223046302795,\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6923 - val_loss: 0.689122712326049805,\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6905 - val_loss: 0.688005147433280945,\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6892 - val_loss: 0.68699213752746582,\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6881 - val_loss: 0.686280539059638977,\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6869 - val_loss: 0.684869416832923889,\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6848 - val_loss: 0.683647726702690125,\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6846 - val_loss: 0.682746482753753662,\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6830 - val_loss: 0.681429968094825745,\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6816 - val_loss: 0.680416432476043701,\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6810 - val_loss: 0.679309656620025635,\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6790 - val_loss: 0.678290016293525696,\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6784 - val_loss: 0.677384214973449707,\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6769 - val_loss: 0.676269329905509949,\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6761 - val_loss: 0.675060954856872559,\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6739 - val_loss: 0.674039253997802734,\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6736 - val_loss: 0.672935789179801941,\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6716 - val_loss: 0.671916137528419495,\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6713 - val_loss: 0.670512913513183594,\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6697 - val_loss: 0.66966979999542236,\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6681 - val_loss: 0.668580895686149597,\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6672 - val_loss: 0.667471757102012634,\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6662 - val_loss: 0.66621787033081055,\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6652 - val_loss: 0.664851663184165955,\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6630 - val_loss: 0.663930085110664368,\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6626 - val_loss: 0.662625890135765076,\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6617 - val_loss: 0.661216703867912292,\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6598 - val_loss: 0.66069768283367157,\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6596 - val_loss: 0.659395701575279236,\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6570 - val_loss: 0.65869690704345703,\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6559 - val_loss: 0.657158818221092224,\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6552 - val_loss: 0.656351752090454102,\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6536 - val_loss: 0.655036203026771545,\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6540 - val_loss: 0.653140047526359558,\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6523 - val_loss: 0.651422811055183411,\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6500 - val_loss: 0.650499715447425842,\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6497 - val_loss: 0.648797089266777039,\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6480 - val_loss: 0.647080181813240051,\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6459 - val_loss: 0.645459385752677917,\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6452 - val_loss: 0.643751826691627502,\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6438 - val_loss: 0.642538072323799133,\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6422 - val_loss: 0.641522114968299866,\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6400 - val_loss: 0.640000452256202698,\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6399 - val_loss: 0.639198876309394836,\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6384 - val_loss: 0.638284106278419495,\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6381 - val_loss: 0.636780576491355896,\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6359 - val_loss: 0.636059320282936096,\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6359 - val_loss: 0.63478950734138489,\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6335 - val_loss: 0.633334630846977234,\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6318 - val_loss: 0.631817672729492188,\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6308 - val_loss: 0.630408380365371704,\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6285 - val_loss: 0.62905225749015808,\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6279 - val_loss: 0.62857946138381958,\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6279 - val_loss: 0.626979430389404297,\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6250 - val_loss: 0.625849627470970154,\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6244 - val_loss: 0.624644087815284729,\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6228 - val_loss: 0.623228091716766357,\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6228 - val_loss: 0.621927879524230957,\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6201 - val_loss: 0.62070104968547821,\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6197 - val_loss: 0.619197106242179871,\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6168 - val_loss: 0.618068238520622253,\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6169 - val_loss: 0.616768723702430725,\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6141 - val_loss: 0.615741312122344971,\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6132 - val_loss: 0.614132002472877502,\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6113 - val_loss: 0.612412533211708069,\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6114 - val_loss: 0.611413924384117126,\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6113 - val_loss: 0.60922801432609558,\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6080 - val_loss: 0.607880021858215332,\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6066 - val_loss: 0.606866429615020752,\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6046 - val_loss: 0.605345947074890137,\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6035 - val_loss: 0.603935236120223999,\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6012 - val_loss: 0.602511711955070496,\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6030 - val_loss: 0.60103035032749176,\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5987 - val_loss: 0.599187352728843689,\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5980 - val_loss: 0.597680233550071716,\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5958 - val_loss: 0.596358308577537537,\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5935 - val_loss: 0.59524893488883972,\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5938 - val_loss: 0.593937662720680237,\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5927 - val_loss: 0.59232670202255249,\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5902 - val_loss: 0.591001545882225037,\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5880 - val_loss: 0.58957956428527832,\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5877 - val_loss: 0.58796935720443726,\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5833 - val_loss: 0.586833413004875183,\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5846 - val_loss: 0.58504575355052948,\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5853 - val_loss: 0.583753109955787659,\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5811 - val_loss: 0.581511026692390442,\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5791 - val_loss: 0.58021146755218506,\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5778 - val_loss: 0.57917938961982727,\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5755 - val_loss: 0.57754707455635071,\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5760 - val_loss: 0.575960229229927063,\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5747 - val_loss: 0.574446901631355286,\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5719 - val_loss: 0.572419296932220459,\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5698 - val_loss: 0.570598089599609375,\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5662 - val_loss: 0.56926152811050415,\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5680 - val_loss: 0.567380038928985596,\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5646 - val_loss: 0.565646300911903381,\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5617 - val_loss: 0.564116994500160217,\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5598 - val_loss: 0.561998342418670654,\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5607 - val_loss: 0.560706690645217896,\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5572 - val_loss: 0.559272386384010315,\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5588 - val_loss: 0.55767683320045471,\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5557 - val_loss: 0.555656762218475342,\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5517 - val_loss: 0.553717331957817078,\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5514 - val_loss: 0.551813980388641357,\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5482 - val_loss: 0.549581712222099304,\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5471 - val_loss: 0.547370975041389465,\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5455 - val_loss: 0.545955396175384521,\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5432 - val_loss: 0.544432372093200684,\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5404 - val_loss: 0.542804236912727356,\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5389 - val_loss: 0.54089464497566223,\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5393 - val_loss: 0.539293317341804504,\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5361 - val_loss: 0.537460903143882751,\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5316 - val_loss: 0.535716024422645569,\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5335 - val_loss: 0.533135238575935364,\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5296 - val_loss: 0.531296116471290588,\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5255 - val_loss: 0.52865485634803772,\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5274 - val_loss: 0.527074482369422913,\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5255 - val_loss: 0.524855200266838074,\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5232 - val_loss: 0.52273207426071167,\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5247 - val_loss: 0.519946599912643433,\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5174 - val_loss: 0.518673537731170654,\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5169 - val_loss: 0.516569360637664795,\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5144 - val_loss: 0.514244355893135071,\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5106 - val_loss: 0.512406151700019836,\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5137 - val_loss: 0.510836990547180176,\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5092 - val_loss: 0.508391502666473389,\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5034 - val_loss: 0.505734055709838867,\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5059 - val_loss: 0.503759376358985901,\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4962 - val_loss: 0.501562488114833832,\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5010 - val_loss: 0.499509707808494568,\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5013 - val_loss: 0.49761259982585907,\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4960 - val_loss: 0.495259763288497925,\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4914 - val_loss: 0.4932913950264453888,\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4911 - val_loss: 0.491291056352853775,\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4899 - val_loss: 0.4894992452025413513,\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4894 - val_loss: 0.487094460439682007,\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4857 - val_loss: 0.4843857405424118042,\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4852 - val_loss: 0.481451821959018707,\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4764 - val_loss: 0.47963663709163666,\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4744 - val_loss: 0.477243705093860626,\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4793 - val_loss: 0.4756930970788002014,\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4710 - val_loss: 0.4733097182273864746,\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4680 - val_loss: 0.470479892957210541,\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4707 - val_loss: 0.4683071340680122375,\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4666 - val_loss: 0.46536661055088043213,\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4636 - val_loss: 0.4635635530412197113,\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4620 - val_loss: 0.4611204352378845215,\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4578 - val_loss: 0.4591779815316200256,\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4556 - val_loss: 0.4572555759131908417,\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4531 - val_loss: 0.4548531265199184418,\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4497 - val_loss: 0.452897425854206085,\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4457 - val_loss: 0.4504456835985183716,\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4509 - val_loss: 0.4479092692971229553,\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4438 - val_loss: 0.445438059329986572,\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4453 - val_loss: 0.4436453347623348236,\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4402 - val_loss: 0.440315148282051086,\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4416 - val_loss: 0.4380155970215797424,\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4392 - val_loss: 0.4362391727149486542,\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4340 - val_loss: 0.4328402114510536194,\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4296 - val_loss: 0.4299295612871646881,\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4265 - val_loss: 0.42812651060223579407,\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4303 - val_loss: 0.4257302595555782318,\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4224 - val_loss: 0.4228223579466342926,\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4235 - val_loss: 0.420034839975833893,\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4191 - val_loss: 0.41761908755898475647,\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4135 - val_loss: 0.4156134778678417206,\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4125 - val_loss: 0.4131253915429115295,\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4151 - val_loss: 0.4106508206725120544,\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4099 - val_loss: 0.408298800718784332,\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4047 - val_loss: 0.40540465298295021057,\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3995 - val_loss: 0.402694676172733307,\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4027 - val_loss: 0.400702652770280838,\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3954 - val_loss: 0.3988954397737979889,\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4001 - val_loss: 0.396301307189464569,\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3980 - val_loss: 0.3932980216681957245,\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3928 - val_loss: 0.390080375838279724,\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3933 - val_loss: 0.387393344908952713,\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3917 - val_loss: 0.384117194604873657,\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3845 - val_loss: 0.381984522408246994,\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3796 - val_loss: 0.37947959274649620056,\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3758 - val_loss: 0.37648341073989868,\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3734 - val_loss: 0.37397336960434913635,\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.39040.3778724670410156, 0.37373366951942444, - 0s 16ms/step - loss: 0.3737 - val_loss: 0.3712\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3733 - val_loss: 0.368928508496284485,\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3668 - val_loss: 0.36706678341031074524,\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3652 - val_loss: 0.36426520373821258545,\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3640 - val_loss: 0.3609400309205055237,\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3601 - val_loss: 0.358801330816745758,\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3616 - val_loss: 0.3570616313934326172,\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3529 - val_loss: 0.354429457747936249,\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3586 - val_loss: 0.3517859179496765137,\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3554 - val_loss: 0.349254213047027588,\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3494 - val_loss: 0.34634942516684532166,\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3510 - val_loss: 0.34495100793838500977,\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3426 - val_loss: 0.342025813913345337,\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3450 - val_loss: 0.3391450378477573395,\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3417 - val_loss: 0.337216941463947296,\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3372 - val_loss: 0.3346372160494327545,\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3403 - val_loss: 0.332102653932571411,\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3335 - val_loss: 0.328935326611995697,\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3322 - val_loss: 0.32653220407366752625,\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3285 - val_loss: 0.3242851454615592957,\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3230 - val_loss: 0.321929609727859497,\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3231 - val_loss: 0.31970680525302887,\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3232 - val_loss: 0.31802316991686820984,\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3245 - val_loss: 0.3154245367705821991,\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3163 - val_loss: 0.31331631550192832947,\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3130 - val_loss: 0.3104303200125694275,\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3145 - val_loss: 0.308544637644290924,\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3072 - val_loss: 0.305871807324886322,\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3060 - val_loss: 0.303459524595737457,\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3015 - val_loss: 0.30080146539211273193,\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3006 - val_loss: 0.2991056917667388916,\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3046 - val_loss: 0.297246455383300781,\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2954 - val_loss: 0.29489537829756736755,\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3017 - val_loss: 0.293016900420188904,\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2990 - val_loss: 0.2899899346828460693,\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2935 - val_loss: 0.2878350194334983826,\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2933 - val_loss: 0.28609326775670051575,\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2871 - val_loss: 0.2838714025020599365,\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2821 - val_loss: 0.28118208884596824646,\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2840 - val_loss: 0.27918397244215011597,\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2815 - val_loss: 0.27708150632977485657,\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.25890.2778794765472412, 0.2827766239643097, - 0s 15ms/step - loss: 0.2828 - val_loss: 0.2755\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2829 - val_loss: 0.2730828696072101593,\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2778 - val_loss: 0.2709777685225009918,\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2669 - val_loss: 0.269568738067150116,\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2713 - val_loss: 0.2681130916714668274,\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2764 - val_loss: 0.266063710916042328,\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2717 - val_loss: 0.262916945707798004,\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2696 - val_loss: 0.2610956668496131897,\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2605 - val_loss: 0.2597604859173297882,\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2610 - val_loss: 0.25791042058467865,\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2557 - val_loss: 0.255756733191013336,\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2616 - val_loss: 0.2536616264522075653,\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2615 - val_loss: 0.2515615388333797455,\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2544 - val_loss: 0.2497440657138824463,\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2548 - val_loss: 0.2477479257106781006,\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2472 - val_loss: 0.24654719510972499847,\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2484 - val_loss: 0.24464844199419021606,\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2587 - val_loss: 0.2428587329149246216,\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2543 - val_loss: 0.2413434410572052,\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2438 - val_loss: 0.23974378550052642822,\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2503 - val_loss: 0.23815032445788383484,\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2464 - val_loss: 0.2356464008927345276,\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2420 - val_loss: 0.23474202950298786163,\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2394 - val_loss: 0.23253943273723125458,\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2422 - val_loss: 0.23104219994246959686,\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2317 - val_loss: 0.229517245602607727,\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2399 - val_loss: 0.2272398814707994461,\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2295 - val_loss: 0.2260294788360595703,\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2273 - val_loss: 0.22422732985019683838,\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2303 - val_loss: 0.22193034489154815674,\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2242 - val_loss: 0.22092417320311069489,\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2278 - val_loss: 0.21972780168056488037,\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2209 - val_loss: 0.21852088934481143951,\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2175 - val_loss: 0.21641753625571727753,\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2200 - val_loss: 0.21491996809542179108,\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2221 - val_loss: 0.2134211988270282745,\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2179 - val_loss: 0.2117791021525859833,\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2152 - val_loss: 0.21031523137390613556,\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2162 - val_loss: 0.2089161572426557541,\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2133 - val_loss: 0.20711332885324954987,\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2161 - val_loss: 0.20561614772081375122,\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2149 - val_loss: 0.204014927077293396,\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2094 - val_loss: 0.2025093975692987442,\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1985 - val_loss: 0.20119852109253406525,\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2065 - val_loss: 0.20030649541914463043,\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2045 - val_loss: 0.1987447169244289398,\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2059 - val_loss: 0.1979058885544538498,\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2057 - val_loss: 0.19690565414428710938,\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1994 - val_loss: 0.19589935546815395355,\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1965 - val_loss: 0.194254728472232819,\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1966 - val_loss: 0.19259655346870422363,\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2054 - val_loss: 0.1911537728071212769,\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1965 - val_loss: 0.18949652509689331055,\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1979 - val_loss: 0.1879794519245624542,\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1977 - val_loss: 0.18669772785902023315,\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1914 - val_loss: 0.18539140879809856415,\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1942 - val_loss: 0.18459421911239624023,\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1887 - val_loss: 0.1835886727213859558,\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1892 - val_loss: 0.18278922030925750732,\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1832 - val_loss: 0.181131747144460678,\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1880 - val_loss: 0.18028795941770076752,\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1860 - val_loss: 0.178659605312347412,\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1891 - val_loss: 0.17748905724585056305,\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1753 - val_loss: 0.176252961426973343,\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1773 - val_loss: 0.1750730368673801422,\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1791 - val_loss: 0.17387911653220653534,\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1858 - val_loss: 0.17228583154678344727,\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1813 - val_loss: 0.17078125081062316895,\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1812 - val_loss: 0.16988123610317707062,\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1773 - val_loss: 0.16917734229564666748,\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1807 - val_loss: 0.1682065494298934937,\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1799 - val_loss: 0.1675799209862947464,\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1759 - val_loss: 0.1666758689284324646,\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1710 - val_loss: 0.16527099718749523163,\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1700 - val_loss: 0.16446997230052947998,\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1684 - val_loss: 0.16336842369735240936,\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1647 - val_loss: 0.16206468775272369385,\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1684 - val_loss: 0.1610836483776569366,\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1698 - val_loss: 0.15997535663843155,\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1671 - val_loss: 0.15926707050800323486,\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1644 - val_loss: 0.158143747240304947,\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1733 - val_loss: 0.15747331337928771973,\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1661 - val_loss: 0.1567611450910568237,\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1621 - val_loss: 0.155208338737487793,\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1611 - val_loss: 0.15426113092005252838,\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1533 - val_loss: 0.15315334534645080566,\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1566 - val_loss: 0.15205660278499126434,\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1642 - val_loss: 0.1513641819030046463,\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1604 - val_loss: 0.1506604161262512207,\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1521 - val_loss: 0.14975206687152385712,\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1510 - val_loss: 0.1487509583443403244,\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1600 - val_loss: 0.14776001607477664948,\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1542 - val_loss: 0.14695418826043605804,\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1475 - val_loss: 0.146174989801645279,\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1530 - val_loss: 0.14515303076803684235,\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1537 - val_loss: 0.14445372192859649658,\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1460 - val_loss: 0.14364596813917160034,\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1478 - val_loss: 0.142778070169687271,\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1445 - val_loss: 0.1416453530311584473,\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1484 - val_loss: 0.1410837537705898285,\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1499 - val_loss: 0.1404498863250017166,\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1524 - val_loss: 0.13955242671966552734,\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1436 - val_loss: 0.13854360226690769196,\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1474 - val_loss: 0.137874469155073166,\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1486 - val_loss: 0.13734855064451694489,\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1459 - val_loss: 0.1368593307673931122,\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1473 - val_loss: 0.13564728844165802002,\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1389 - val_loss: 0.1347886527717113495,\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1380 - val_loss: 0.13423801419734954834,\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1395 - val_loss: 0.1331950423896312714,\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1442 - val_loss: 0.13274423353970050812,\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1360 - val_loss: 0.13183602586090564728,\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1397 - val_loss: 0.1311397368311882019,\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1367 - val_loss: 0.1304671070337295532,\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1297 - val_loss: 0.1295966741621494293,\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1364 - val_loss: 0.1286643141090869904,\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1334 - val_loss: 0.12803342994451522827,\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1309 - val_loss: 0.1272086940348148346,\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1322 - val_loss: 0.1264322334259748459,\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1343 - val_loss: 0.12593432465493679047,\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1304 - val_loss: 0.12533043178617954254,\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1284 - val_loss: 0.12452836073338985443,\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1329 - val_loss: 0.1243329275220632553,\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1300 - val_loss: 0.1235002946972846985,\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1363 - val_loss: 0.1231363074630498886,\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1241 - val_loss: 0.12242409621477127075,\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1281 - val_loss: 0.122228058061003685,\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1360 - val_loss: 0.1218359800547361374,\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1222 - val_loss: 0.12072221898883581161,\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1284 - val_loss: 0.1200284041702747345,\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1254 - val_loss: 0.119254003793001175,\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1229 - val_loss: 0.1187286224216222763,\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1268 - val_loss: 0.11832676958739757538,\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1229 - val_loss: 0.11782290108948945999,\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1267 - val_loss: 0.1172266680210828781,\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1221 - val_loss: 0.11672213916331529617,\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1229 - val_loss: 0.11602293782085180283,\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1205 - val_loss: 0.11532053874135017395,\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1239 - val_loss: 0.11482390819936990738,\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1148 - val_loss: 0.11411483470350503922,\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1203 - val_loss: 0.1134033525854349136,\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1177 - val_loss: 0.1130770111322402954,\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1165 - val_loss: 0.1123645609885454178,\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1238 - val_loss: 0.11202383928149938583,\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1105 - val_loss: 0.11141046711355447769,\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1192 - val_loss: 0.1109920703202486038,\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1240 - val_loss: 0.11062400207668542862,\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1126 - val_loss: 0.109912601138651371,\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1097 - val_loss: 0.10910968045145273209,\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1127 - val_loss: 0.10861265367269515991,\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1185 - val_loss: 0.10811854013055562973,\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1139 - val_loss: 0.1075392880231142044,\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1144 - val_loss: 0.10701442535370588303,\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1244 - val_loss: 0.10682443441152572632,\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1106 - val_loss: 0.10611056894063949585,\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1143 - val_loss: 0.1056142837405204773,\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1141 - val_loss: 0.10551409598588943481,\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1107 - val_loss: 0.10491065445095300674,\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1172 - val_loss: 0.1047172156110405922,\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1076 - val_loss: 0.10420760771483182907,\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1079 - val_loss: 0.10360786250978708267,\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1090 - val_loss: 0.103200673270225525,\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1040 - val_loss: 0.10280404638200998306,\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1128 - val_loss: 0.10231281325668096542,\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1126 - val_loss: 0.10191264591664075851,\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1007 - val_loss: 0.10150074123740196228,\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1105 - val_loss: 0.10121048891395330429,\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1087 - val_loss: 0.1007086568534374237,\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1058 - val_loss: 0.1001058359369635582,\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1032 - val_loss: 0.09940324442386627197,\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1102 - val_loss: 0.0990016712337732315,\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1097 - val_loss: 0.0986965404659509659,\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1079 - val_loss: 0.09800785403102636337,\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1006 - val_loss: 0.09760062342882156372,\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1050 - val_loss: 0.0972502206534147263,\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1080 - val_loss: 0.09680799521207809448,\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1066 - val_loss: 0.09650664597153663635,\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0999 - val_loss: 0.09609987793117761612,\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1003 - val_loss: 0.09550027080029249191,\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1006 - val_loss: 0.09520057679563760757,\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0988 - val_loss: 0.09499879833459854126,\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1028 - val_loss: 0.09470277657955884933,\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1005 - val_loss: 0.09410048931837081909,\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1031 - val_loss: 0.09370305529087781906,\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0991 - val_loss: 0.09329911935776472092,\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0943 - val_loss: 0.0928432294219732285,\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0940 - val_loss: 0.0926940224751830101,\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0940 - val_loss: 0.09239400469809770584,\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0972 - val_loss: 0.0919972142443060875,\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0951 - val_loss: 0.09159512849897146225,\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0977 - val_loss: 0.0910772661328315735,\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0990 - val_loss: 0.09079902558475732803,\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0948 - val_loss: 0.090394795823097229,\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1122 - val_loss: 0.09011220741271972656,\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0969 - val_loss: 0.0897691843390464783,\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0948 - val_loss: 0.08939480654448270798,\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0941 - val_loss: 0.08899411375969648361,\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1010 - val_loss: 0.08850100562125444412,\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0936 - val_loss: 0.0881358879923820496,\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0950 - val_loss: 0.08779502384811639786,\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0992 - val_loss: 0.08759920596331357956,\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0923 - val_loss: 0.08729225975722074509,\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0898 - val_loss: 0.0869979064226150513,\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0907 - val_loss: 0.0865906858742237091,\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0908 - val_loss: 0.08619083327651023865,\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0902 - val_loss: 0.0860019827842712402,\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0912 - val_loss: 0.08579117362648248672,\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0895 - val_loss: 0.08548947174996137619,\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0903 - val_loss: 0.085128512984514236,\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0929 - val_loss: 0.08479294057637453079,\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0905 - val_loss: 0.08449048353880643845,\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0856 - val_loss: 0.08418558707684278488,\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0898 - val_loss: 0.08398982285112142563,\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0872 - val_loss: 0.08358721492439508438,\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0866 - val_loss: 0.08328662467449903488,\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0833 - val_loss: 0.08288326845616102219,\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0956 - val_loss: 0.08269560936689376831,\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0982 - val_loss: 0.08249816793352365494,\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0858 - val_loss: 0.08208579039573669434,\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0841 - val_loss: 0.081840807780623436,\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0932 - val_loss: 0.08169323734790086746,\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0833 - val_loss: 0.08138332260698080063,\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0834 - val_loss: 0.08108337411284446716,\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0828 - val_loss: 0.0807828060507774353,\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0885 - val_loss: 0.08058849829435348511,\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0895 - val_loss: 0.08018954348415136337,\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0834 - val_loss: 0.07978344510942697525,\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0955 - val_loss: 0.07969554978460073471,\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0812 - val_loss: 0.07938124606311321259,\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0803 - val_loss: 0.07898032753318548203,\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0849 - val_loss: 0.07868493047952651978,\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0826 - val_loss: 0.0784260168880224228,\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0874 - val_loss: 0.07828735236525535583,\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0788 - val_loss: 0.07817875295728445053,\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0800 - val_loss: 0.07787995180040597916,\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0851 - val_loss: 0.07768513292670249939,\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0871 - val_loss: 0.07748707170933485031,\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0936 - val_loss: 0.07729359965473413467,\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0845 - val_loss: 0.0770845041275024414,\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0782 - val_loss: 0.07677816469669342041,\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0772 - val_loss: 0.07647721053808927536,\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0780 - val_loss: 0.07617796741276979446,\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0821 - val_loss: 0.07588208458870649338,\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0795 - val_loss: 0.07557946016639471054,\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0783 - val_loss: 0.0752783325731754303,\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0810 - val_loss: 0.07518102306723594666,\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0790 - val_loss: 0.07487897976785898209,\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0846 - val_loss: 0.07488458200842142105,\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0791 - val_loss: 0.0746791410580277443,\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0821 - val_loss: 0.0746208932727575302,\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0856 - val_loss: 0.0743855882465839386,\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0823 - val_loss: 0.07408233905583620071,\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0769 - val_loss: 0.0738692161947488785,\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0770 - val_loss: 0.07357699883729219437,\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0855 - val_loss: 0.0733545691519975662,\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0780 - val_loss: 0.0730780220553278923,\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0802 - val_loss: 0.07298022262901067734,\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0786 - val_loss: 0.07287862890511751175,\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0845 - val_loss: 0.07258446984738111496,\n"
     ]
    }
   ],
   "source": [
    "train(both_data, both_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f459859d128>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1120x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot losses\n",
    "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "size = len(lr.losses)\n",
    "ax.plot(range(0,size), lr.losses, '-', color='blue', animated = True, linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# get validation data for winter 2014-2015\n",
    "winter_val_data = spark.sql(\"\"\"\n",
    "    select *\n",
    "        from pjm_AEP_normalized \n",
    "        where unix_timestamp(day, \"yyyy-MM-dd\") >= unix_timestamp(\"2014-12-01\", \"yyyy-MM-dd\")AND\n",
    "              unix_timestamp(day, \"yyyy-MM-dd\") <= unix_timestamp(\"2015-02-28\", \"yyyy-MM-dd\")\n",
    "        \n",
    "    \"\"\")\n",
    "print(winter_val_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# get validation data for summer 2015\n",
    "summer_val_data = spark.sql(\"\"\"\n",
    "    select *\n",
    "        from pjm_AEP_normalized \n",
    "        where unix_timestamp(day, \"yyyy-MM-dd\") >= unix_timestamp(\"2015-06-01\", \"yyyy-MM-dd\")AND\n",
    "              unix_timestamp(day, \"yyyy-MM-dd\") <= unix_timestamp(\"2015-08-29\", \"yyyy-MM-dd\")\n",
    "        \n",
    "    \"\"\")\n",
    "print(summer_val_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_val_data = np.array(winter_val_data.select(\n",
    "    \"h_0\", \"h_1\", \"h_2\", \"h_3\", \"h_4\", \"h_5\", \"h_6\", \"h_7\", \"h_8\", \"h_9\", \"h_10\", \"h_11\",\n",
    "    \"h_12\", \"h_13\", \"h_14\", \"h_15\", \"h_16\", \"h_17\", \"h_18\", \"h_19\", \"h_20\", \"h_21\", \"h_22\", \"h_23\"    \n",
    "    ).collect())\n",
    "\n",
    "summer_val_data = np.array(summer_val_data.select(\n",
    "    \"h_0\", \"h_1\", \"h_2\", \"h_3\", \"h_4\", \"h_5\", \"h_6\", \"h_7\", \"h_8\", \"h_9\", \"h_10\", \"h_11\",\n",
    "    \"h_12\", \"h_13\", \"h_14\", \"h_15\", \"h_16\", \"h_17\", \"h_18\", \"h_19\", \"h_20\", \"h_21\", \"h_22\", \"h_23\"    \n",
    "    ).collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1116\n",
      "test loss, test acc: 0.11159682273864746\n"
     ]
    }
   ],
   "source": [
    "val_data = np.vstack((winter_val_data, summer_val_data))\n",
    "\n",
    "results = model.evaluate(val_data, both_label)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 180 \n",
      "positives: 175 \n",
      "negatives: 5\n",
      "accuracy: 97.22%\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(val_data)\n",
    "prediction_with_lab= np.hstack((prediction, both_label))\n",
    "\n",
    "positives = 0\n",
    "negatives = 0\n",
    "\n",
    "for item in prediction_with_lab:\n",
    "    p = item[0] #prediction\n",
    "    l = item[1] #label\n",
    "    if l == 1:  #winter label\n",
    "        if p > 0.5:\n",
    "            positives += 1\n",
    "        else:\n",
    "            negatives += 1\n",
    "\n",
    "    if l == 0:  #summer label\n",
    "        if p < 0.5:\n",
    "            positives += 1\n",
    "        else:\n",
    "            negatives += 1\n",
    "            \n",
    "            \n",
    "print(format('total: %d ' % len(prediction_with_lab)))\n",
    "print(format('positives: %d \\nnegatives: %d' % (positives, negatives)))\n",
    "\n",
    "accuracy = positives / len(prediction_with_lab) * 100\n",
    "\n",
    "print(format('accuracy: %.2f%%' % accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44142964],\n",
       "       [0.69176227],\n",
       "       [0.5448546 ],\n",
       "       [0.15204883],\n",
       "       [0.07775983],\n",
       "       [0.28122807],\n",
       "       [0.07027027],\n",
       "       [0.20493838],\n",
       "       [0.14139551],\n",
       "       [0.02321151],\n",
       "       [0.01494145],\n",
       "       [0.04410672],\n",
       "       [0.03456441],\n",
       "       [0.0257501 ],\n",
       "       [0.02161121],\n",
       "       [0.06694824],\n",
       "       [0.3134929 ],\n",
       "       [0.02158344],\n",
       "       [0.2632087 ],\n",
       "       [0.18034011],\n",
       "       [0.0337896 ],\n",
       "       [0.01274058],\n",
       "       [0.07102618],\n",
       "       [0.04263815],\n",
       "       [0.13794318],\n",
       "       [0.19827995],\n",
       "       [0.6174451 ],\n",
       "       [0.27512196],\n",
       "       [0.29973117],\n",
       "       [0.13730034],\n",
       "       [0.12724212],\n",
       "       [0.46232998],\n",
       "       [0.30439618],\n",
       "       [0.11104044],\n",
       "       [0.08968866],\n",
       "       [0.02562091],\n",
       "       [0.06503949],\n",
       "       [0.4008288 ],\n",
       "       [0.1688115 ],\n",
       "       [0.17842558],\n",
       "       [0.07641542],\n",
       "       [0.10109243],\n",
       "       [0.07306206],\n",
       "       [0.08503601],\n",
       "       [0.25150058],\n",
       "       [0.0960463 ],\n",
       "       [0.02023935],\n",
       "       [0.0191294 ],\n",
       "       [0.0216772 ],\n",
       "       [0.01563451],\n",
       "       [0.07799456],\n",
       "       [0.04521209],\n",
       "       [0.03069127],\n",
       "       [0.01963323],\n",
       "       [0.02238309],\n",
       "       [0.02228785],\n",
       "       [0.01979598],\n",
       "       [0.00938669],\n",
       "       [0.01102036],\n",
       "       [0.04506803],\n",
       "       [0.02033508],\n",
       "       [0.04467621],\n",
       "       [0.02972785],\n",
       "       [0.0195691 ],\n",
       "       [0.02166718],\n",
       "       [0.02251616],\n",
       "       [0.5187782 ],\n",
       "       [0.11594298],\n",
       "       [0.03922686],\n",
       "       [0.03547433],\n",
       "       [0.0640417 ],\n",
       "       [0.07760924],\n",
       "       [0.11075723],\n",
       "       [0.04808936],\n",
       "       [0.02443609],\n",
       "       [0.02931339],\n",
       "       [0.02135429],\n",
       "       [0.01855659],\n",
       "       [0.09908178],\n",
       "       [0.02571785],\n",
       "       [0.3655265 ],\n",
       "       [0.125918  ],\n",
       "       [0.07275593],\n",
       "       [0.04772407],\n",
       "       [0.12803784],\n",
       "       [0.43206304],\n",
       "       [0.5474272 ],\n",
       "       [0.40577954],\n",
       "       [0.11878734],\n",
       "       [0.05970794]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(summer_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  5]\n",
      " [ 0 90]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = prediction > 0.5      #clf.predict(X_test)\n",
    "cm = confusion_matrix(both_label, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "labels = ['summer', 'winter']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      summer       1.00      0.94      0.97        90\n",
      "      winter       0.95      1.00      0.97        90\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       180\n",
      "   macro avg       0.97      0.97      0.97       180\n",
      "weighted avg       0.97      0.97      0.97       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = ['summer', 'winter']\n",
    "print(classification_report(both_label, y_pred, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
